{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
    "\n",
    "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
    "\n",
    "This notebook was generated for TensorFlow 2.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Modern convnet architecture patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Modularity, hierarchy, and reuse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Residual connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Residual block where the number of filters changes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n",
    "# 残差\n",
    "residual = x\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "residual = layers.Conv2D(64, 1)(residual)\n",
    "x = layers.add([x, residual])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Case where target block includes a max pooling layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n",
    "residual = x\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.MaxPooling2D(2, padding=\"same\")(x)\n",
    "# 在残差投影中使用strides=2，以匹配最大汇聚层导致的下采样\n",
    "residual = layers.Conv2D(64, 1, strides=2)(residual)\n",
    "x = layers.add([x, residual])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " rescaling (Rescaling)          (None, 32, 32, 3)    0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 32, 32, 32)   896         ['rescaling[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 32, 32, 32)   9248        ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 32)  0           ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 16, 16, 32)   128         ['rescaling[0][0]']              \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 16, 16, 32)   0           ['max_pooling2d_1[0][0]',        \n",
      "                                                                  'conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 16, 16, 64)   18496       ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 16, 16, 64)   36928       ['conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 64)    0           ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 8, 8, 64)     2112        ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 8, 8, 64)     0           ['max_pooling2d_2[0][0]',        \n",
      "                                                                  'conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 8, 8, 128)    73856       ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 8, 8, 128)    147584      ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 8, 8, 128)    8320        ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 8, 8, 128)    0           ['conv2d_13[0][0]',              \n",
      "                                                                  'conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 128)         0           ['add_4[0][0]']                  \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            129         ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 297,697\n",
      "Trainable params: 297,697\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "x = layers.Rescaling(1./255)(inputs)\n",
    "\n",
    "def residual_block(x, filters, pooling=False):\n",
    "    residual = x\n",
    "    x = layers.Conv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    if pooling:\n",
    "        # 如果使用最大汇聚，则添加一个步进卷积，将残差投影为想要的形状\n",
    "        x = layers.MaxPooling2D(2, padding=\"same\")(x)\n",
    "        residual = layers.Conv2D(filters, 1, strides=2)(residual)\n",
    "    elif filters != residual.shape[-1]:\n",
    "        residual = layers.Conv2D(filters, 1)(residual)\n",
    "    x = layers.add([x, residual])\n",
    "    return x\n",
    "\n",
    "x = residual_block(x, filters=32, pooling=True)\n",
    "x = residual_block(x, filters=64, pooling=True)\n",
    "x = residual_block(x, filters=128, pooling=False)\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Batch normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Depthwise separable convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Putting it together: A mini Xception-like model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 files belonging to 2 classes.\n",
      "Found 1000 files belonging to 2 classes.\n",
      "Found 1000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import os, shutil, pathlib\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "new_base_dir = pathlib.Path(\"../data/cats_vs_dogs_small\")\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"train\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"validation\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"test\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.2),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "code",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(180, 180, 3))\n",
    "x = data_augmentation(inputs)\n",
    "\n",
    "x = layers.Rescaling(1./255)(x)\n",
    "x = layers.Conv2D(filters=32, kernel_size=5, use_bias=False)(x)\n",
    "\n",
    "for size in [32, 64, 128, 256, 512]:\n",
    "    residual = x\n",
    "\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    # 由于后面会将Conv2D层的输出规范化，所以该层不需要偏置向量\n",
    "    x = layers.SeparableConv2D(size, 3, padding=\"same\", use_bias=False)(x)\n",
    "\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    # 将激活放在BN之后\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.SeparableConv2D(size, 3, padding=\"same\", use_bias=False)(x)\n",
    "    \n",
    "    x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "    residual = layers.Conv2D(\n",
    "        size, 1, strides=2, padding=\"same\", use_bias=False)(residual)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "# 添加dropout层进行正则化\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "code",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "63/63 [==============================] - 25s 303ms/step - loss: 0.7080 - accuracy: 0.5685 - val_loss: 0.6946 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 19s 298ms/step - loss: 0.6596 - accuracy: 0.6080 - val_loss: 0.6987 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 19s 300ms/step - loss: 0.6455 - accuracy: 0.6230 - val_loss: 0.7148 - val_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 19s 300ms/step - loss: 0.6232 - accuracy: 0.6395 - val_loss: 0.7081 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 19s 303ms/step - loss: 0.6069 - accuracy: 0.6680 - val_loss: 0.7315 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 19s 302ms/step - loss: 0.5774 - accuracy: 0.6975 - val_loss: 0.7438 - val_accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 19s 305ms/step - loss: 0.5718 - accuracy: 0.7125 - val_loss: 0.8261 - val_accuracy: 0.5080\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 19s 304ms/step - loss: 0.5381 - accuracy: 0.7315 - val_loss: 0.7205 - val_accuracy: 0.5500\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 19s 305ms/step - loss: 0.5373 - accuracy: 0.7325 - val_loss: 0.5712 - val_accuracy: 0.7080\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 19s 304ms/step - loss: 0.5148 - accuracy: 0.7545 - val_loss: 0.8548 - val_accuracy: 0.6100\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 19s 304ms/step - loss: 0.4958 - accuracy: 0.7680 - val_loss: 0.5440 - val_accuracy: 0.7200\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 19s 304ms/step - loss: 0.4724 - accuracy: 0.7870 - val_loss: 1.1122 - val_accuracy: 0.5620\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 19s 307ms/step - loss: 0.4524 - accuracy: 0.7890 - val_loss: 0.8565 - val_accuracy: 0.6370\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 20s 310ms/step - loss: 0.4687 - accuracy: 0.7765 - val_loss: 0.7320 - val_accuracy: 0.6410\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 20s 309ms/step - loss: 0.4416 - accuracy: 0.7930 - val_loss: 0.4837 - val_accuracy: 0.7750\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 20s 309ms/step - loss: 0.4229 - accuracy: 0.8175 - val_loss: 1.4642 - val_accuracy: 0.5840\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 19s 307ms/step - loss: 0.4269 - accuracy: 0.8040 - val_loss: 0.4769 - val_accuracy: 0.7830\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 19s 306ms/step - loss: 0.4046 - accuracy: 0.8240 - val_loss: 1.3044 - val_accuracy: 0.5650\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 19s 309ms/step - loss: 0.3841 - accuracy: 0.8290 - val_loss: 0.5915 - val_accuracy: 0.7000\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 20s 309ms/step - loss: 0.3966 - accuracy: 0.8230 - val_loss: 0.7844 - val_accuracy: 0.6490\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 19s 306ms/step - loss: 0.3551 - accuracy: 0.8460 - val_loss: 0.6436 - val_accuracy: 0.7210\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 19s 306ms/step - loss: 0.3639 - accuracy: 0.8345 - val_loss: 0.6580 - val_accuracy: 0.7150\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 19s 307ms/step - loss: 0.3502 - accuracy: 0.8440 - val_loss: 0.7471 - val_accuracy: 0.7110\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 19s 308ms/step - loss: 0.3536 - accuracy: 0.8455 - val_loss: 0.6424 - val_accuracy: 0.7150\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 19s 308ms/step - loss: 0.3289 - accuracy: 0.8615 - val_loss: 0.7379 - val_accuracy: 0.7140\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 19s 307ms/step - loss: 0.3329 - accuracy: 0.8555 - val_loss: 0.4091 - val_accuracy: 0.8210\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 19s 308ms/step - loss: 0.3050 - accuracy: 0.8680 - val_loss: 0.8753 - val_accuracy: 0.6780\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 19s 306ms/step - loss: 0.3115 - accuracy: 0.8605 - val_loss: 0.8670 - val_accuracy: 0.6780\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 19s 308ms/step - loss: 0.3107 - accuracy: 0.8660 - val_loss: 1.0734 - val_accuracy: 0.6210\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 19s 308ms/step - loss: 0.3047 - accuracy: 0.8650 - val_loss: 0.6533 - val_accuracy: 0.7800\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 19s 307ms/step - loss: 0.3035 - accuracy: 0.8740 - val_loss: 1.0774 - val_accuracy: 0.6830\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 19s 308ms/step - loss: 0.2708 - accuracy: 0.8850 - val_loss: 0.6323 - val_accuracy: 0.7720\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 19s 307ms/step - loss: 0.2847 - accuracy: 0.8815 - val_loss: 1.1509 - val_accuracy: 0.6600\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 19s 307ms/step - loss: 0.2526 - accuracy: 0.8920 - val_loss: 0.4951 - val_accuracy: 0.8060\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 19s 308ms/step - loss: 0.2487 - accuracy: 0.8935 - val_loss: 0.6468 - val_accuracy: 0.7780\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 19s 308ms/step - loss: 0.2338 - accuracy: 0.9040 - val_loss: 0.4866 - val_accuracy: 0.8260\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 19s 308ms/step - loss: 0.2440 - accuracy: 0.9020 - val_loss: 0.9509 - val_accuracy: 0.7360\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 20s 310ms/step - loss: 0.2331 - accuracy: 0.9140 - val_loss: 0.3826 - val_accuracy: 0.8360\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 19s 308ms/step - loss: 0.2293 - accuracy: 0.9045 - val_loss: 0.6314 - val_accuracy: 0.8080\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 20s 310ms/step - loss: 0.2254 - accuracy: 0.9085 - val_loss: 0.4537 - val_accuracy: 0.8240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "63/63 [==============================] - 19s 307ms/step - loss: 0.2222 - accuracy: 0.9150 - val_loss: 0.8976 - val_accuracy: 0.7400\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 19s 309ms/step - loss: 0.2080 - accuracy: 0.9130 - val_loss: 0.9678 - val_accuracy: 0.6470\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 19s 307ms/step - loss: 0.1999 - accuracy: 0.9115 - val_loss: 0.7147 - val_accuracy: 0.7870\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 20s 311ms/step - loss: 0.2024 - accuracy: 0.9200 - val_loss: 0.5173 - val_accuracy: 0.8130\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 19s 307ms/step - loss: 0.2048 - accuracy: 0.9130 - val_loss: 0.7294 - val_accuracy: 0.7860\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 28s 446ms/step - loss: 0.2121 - accuracy: 0.9050 - val_loss: 0.3828 - val_accuracy: 0.8510\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 20s 312ms/step - loss: 0.1867 - accuracy: 0.9200 - val_loss: 0.5419 - val_accuracy: 0.8120\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 20s 311ms/step - loss: 0.1772 - accuracy: 0.9260 - val_loss: 0.8936 - val_accuracy: 0.7660\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 19s 308ms/step - loss: 0.1726 - accuracy: 0.9335 - val_loss: 0.4749 - val_accuracy: 0.8120\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 20s 311ms/step - loss: 0.1548 - accuracy: 0.9415 - val_loss: 0.7656 - val_accuracy: 0.8140\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 20s 309ms/step - loss: 0.1961 - accuracy: 0.9210 - val_loss: 0.8739 - val_accuracy: 0.8090\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 20s 309ms/step - loss: 0.1628 - accuracy: 0.9360 - val_loss: 0.4236 - val_accuracy: 0.8450\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 19s 309ms/step - loss: 0.1788 - accuracy: 0.9320 - val_loss: 1.1246 - val_accuracy: 0.7470\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 20s 309ms/step - loss: 0.1844 - accuracy: 0.9265 - val_loss: 0.5027 - val_accuracy: 0.8380\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 20s 310ms/step - loss: 0.1787 - accuracy: 0.9255 - val_loss: 1.0157 - val_accuracy: 0.7450\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 20s 311ms/step - loss: 0.1491 - accuracy: 0.9410 - val_loss: 0.4786 - val_accuracy: 0.8390\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 20s 309ms/step - loss: 0.1584 - accuracy: 0.9350 - val_loss: 1.0230 - val_accuracy: 0.7210\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 19s 308ms/step - loss: 0.1534 - accuracy: 0.9370 - val_loss: 0.5136 - val_accuracy: 0.8540\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 19s 308ms/step - loss: 0.1431 - accuracy: 0.9410 - val_loss: 0.6563 - val_accuracy: 0.7630\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 20s 309ms/step - loss: 0.1492 - accuracy: 0.9430 - val_loss: 0.6188 - val_accuracy: 0.8320\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 20s 311ms/step - loss: 0.1460 - accuracy: 0.9400 - val_loss: 0.5331 - val_accuracy: 0.8300\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 20s 314ms/step - loss: 0.1334 - accuracy: 0.9490 - val_loss: 0.5254 - val_accuracy: 0.8560\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 21s 340ms/step - loss: 0.1455 - accuracy: 0.9435 - val_loss: 0.9624 - val_accuracy: 0.7340\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 22s 341ms/step - loss: 0.1494 - accuracy: 0.9385 - val_loss: 0.6138 - val_accuracy: 0.8120\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 22s 343ms/step - loss: 0.1649 - accuracy: 0.9365 - val_loss: 1.4388 - val_accuracy: 0.7300\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 21s 339ms/step - loss: 0.1429 - accuracy: 0.9465 - val_loss: 1.0793 - val_accuracy: 0.7590\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 22s 345ms/step - loss: 0.1344 - accuracy: 0.9520 - val_loss: 1.2104 - val_accuracy: 0.7350\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 21s 325ms/step - loss: 0.1207 - accuracy: 0.9535 - val_loss: 0.5790 - val_accuracy: 0.8140\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 20s 312ms/step - loss: 0.1214 - accuracy: 0.9510 - val_loss: 0.4910 - val_accuracy: 0.8490\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 20s 312ms/step - loss: 0.1355 - accuracy: 0.9490 - val_loss: 0.4053 - val_accuracy: 0.8590\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 20s 311ms/step - loss: 0.1061 - accuracy: 0.9585 - val_loss: 0.4887 - val_accuracy: 0.8380\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 19s 309ms/step - loss: 0.1267 - accuracy: 0.9515 - val_loss: 0.5025 - val_accuracy: 0.8510\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 20s 309ms/step - loss: 0.1054 - accuracy: 0.9575 - val_loss: 1.3356 - val_accuracy: 0.7410\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 20s 309ms/step - loss: 0.1234 - accuracy: 0.9535 - val_loss: 0.7573 - val_accuracy: 0.8200\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 20s 311ms/step - loss: 0.1334 - accuracy: 0.9480 - val_loss: 1.6477 - val_accuracy: 0.6860\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 25s 391ms/step - loss: 0.0955 - accuracy: 0.9665 - val_loss: 0.4277 - val_accuracy: 0.8770\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 23s 311ms/step - loss: 0.1202 - accuracy: 0.9560 - val_loss: 0.4703 - val_accuracy: 0.8780\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 20s 311ms/step - loss: 0.1171 - accuracy: 0.9585 - val_loss: 0.5610 - val_accuracy: 0.8300\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 20s 312ms/step - loss: 0.1024 - accuracy: 0.9630 - val_loss: 0.5858 - val_accuracy: 0.8600\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 20s 312ms/step - loss: 0.0909 - accuracy: 0.9620 - val_loss: 0.4760 - val_accuracy: 0.8610\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 20s 311ms/step - loss: 0.1173 - accuracy: 0.9555 - val_loss: 0.5645 - val_accuracy: 0.8510\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 20s 313ms/step - loss: 0.1011 - accuracy: 0.9640 - val_loss: 0.5155 - val_accuracy: 0.8430\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 30s 472ms/step - loss: 0.1036 - accuracy: 0.9630 - val_loss: 0.4296 - val_accuracy: 0.8650\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 20s 312ms/step - loss: 0.1041 - accuracy: 0.9595 - val_loss: 0.6568 - val_accuracy: 0.8330\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 20s 312ms/step - loss: 0.1068 - accuracy: 0.9635 - val_loss: 1.4674 - val_accuracy: 0.7460\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 20s 312ms/step - loss: 0.0899 - accuracy: 0.9710 - val_loss: 1.2992 - val_accuracy: 0.7480\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 20s 311ms/step - loss: 0.0889 - accuracy: 0.9655 - val_loss: 0.5309 - val_accuracy: 0.8730\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 20s 312ms/step - loss: 0.0982 - accuracy: 0.9610 - val_loss: 1.2774 - val_accuracy: 0.7360\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 20s 314ms/step - loss: 0.0996 - accuracy: 0.9640 - val_loss: 0.4578 - val_accuracy: 0.8700\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 20s 310ms/step - loss: 0.0696 - accuracy: 0.9710 - val_loss: 0.5108 - val_accuracy: 0.8500\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 20s 312ms/step - loss: 0.1085 - accuracy: 0.9610 - val_loss: 0.3664 - val_accuracy: 0.8820\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 20s 314ms/step - loss: 0.0983 - accuracy: 0.9595 - val_loss: 0.8524 - val_accuracy: 0.8040\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 20s 311ms/step - loss: 0.0915 - accuracy: 0.9635 - val_loss: 0.3950 - val_accuracy: 0.8780\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 20s 310ms/step - loss: 0.0995 - accuracy: 0.9650 - val_loss: 0.4524 - val_accuracy: 0.8720\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 20s 317ms/step - loss: 0.0997 - accuracy: 0.9620 - val_loss: 0.5466 - val_accuracy: 0.8700\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 20s 311ms/step - loss: 0.0685 - accuracy: 0.9745 - val_loss: 0.6875 - val_accuracy: 0.8200\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 20s 312ms/step - loss: 0.0990 - accuracy: 0.9680 - val_loss: 1.9785 - val_accuracy: 0.7180\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 20s 311ms/step - loss: 0.0929 - accuracy: 0.9660 - val_loss: 0.4897 - val_accuracy: 0.8690\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 20s 309ms/step - loss: 0.0805 - accuracy: 0.9715 - val_loss: 0.4183 - val_accuracy: 0.8720\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 19s 308ms/step - loss: 0.0858 - accuracy: 0.9665 - val_loss: 0.5403 - val_accuracy: 0.8740\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=100,\n",
    "    validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter09_part02_modern-convnet-architecture-patterns.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
